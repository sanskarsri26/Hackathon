import os
import re
import random
from flask import Flask, request, jsonify, send_file, send_from_directory
from google.ai import generativelanguage_v1beta as glm
from google.api_core import client_options as client_options_lib
from gtts import gTTS
import tempfile
from dotenv import load_dotenv

# Load environment variables from a .env file
load_dotenv()

# Create a Flask app
app = Flask(__name__)

# Load API key for Gemini AI from environment variables
api_key = os.getenv("GEMINI_API_KEY")

# Set up client options for the Google Gemini AI API
client_options = client_options_lib.ClientOptions(
    api_endpoint="generativelanguage.googleapis.com", api_key=api_key
)

# Initialize the Google Gemini AI Client
client = glm.GenerativeServiceClient(client_options=client_options)

# System prompt used to guide the AI to act as an MUN debate coach
system_prompt = """
You are an AI debate coach designed to help users prepare for Model United Nations (MUNs).

Upon receiving the user's input about a specific topic and their country, you will:
1. As the Chair, introduce the topic and frame the context for discussion.
2. Assign the roles of three ambassadors based on the most relevant countries for the topic, excluding the user's country.
3. Each ambassador will introduce themselves and present their stance.
4. Once all ambassadors have spoken, the Chair will ask if the user wants to speak.
5. After the user speaks, the ambassadors will respond or present new arguments.

Adapt your responses based on the user's input and debate flow.
"""

# Global variables to store conversation state
conversation_history = [
    glm.Content(parts=[glm.Part(text=system_prompt)], role="user"),
    glm.Content(
        parts=[
            glm.Part(
                text="Understood. Please provide a topic for our MUN debate, and I'll prepare responses accordingly."
            )
        ],
        role="model",
    ),
]

user_country = ""  # Stores the user's country
debate_stage = 0  # Tracks the stage of the debate (0 = topic input, 1 = debate)
topic = ""  # Stores the current debate topic

# Function to clean up AI-generated responses (remove unwanted formatting)
def clean_response(text):
    unwanted_phrases = ["Discussion:", "Analysis:", "Conclusion:", "Summary:"]
    for phrase in unwanted_phrases:
        text = text.replace(phrase, "")
    text = re.sub(r"#{1,6}\s?", "", text)
    text = re.sub(r"[*_]{1,2}", "", text)
    text = re.sub(r"^\s*[-*+]\s|\d+\.\s", "", text, flags=re.MULTILINE)
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r"[^\w\s.,?!]", "", text)
    return text.strip()

# Function to interact with Gemini AI API and get a response based on the prompt
def get_gemini_response(prompt):
    global conversation_history
    if not prompt.strip():
        return "Please provide a non-empty message."
    try:
        system_instruction = "Please provide concise responses of about 50 words or less."
        conversation_history.append(
            glm.Content(parts=[glm.Part(text=system_instruction + "\n\n" + prompt)], role="user")
        )
        request = glm.GenerateContentRequest(
            model="models/gemini-pro",
            contents=conversation_history,
        )
        # Call the AI service and get the response
        response = client.generate_content(request)
        raw_response = response.candidates[0].content.parts[0].text
        cleaned_response = clean_response(raw_response)
        # Save the cleaned response to the conversation history
        conversation_history.append(
            glm.Content(parts=[glm.Part(text=cleaned_response)], role="model")
        )
        return cleaned_response
    except Exception as e:
        print(f"Error in get_gemini_response: {type(e).__name__}: {str(e)}")
        return f"An error occurred while processing your request: {type(e).__name__}. Please try again."

# Function to assign relevant countries for the debate based on the topic
def assign_countries_based_on_topic(topic, user_country):
    prompt = f"""
    Given the topic '{topic}' and the user's country '{user_country}', 
    please suggest three relevant countries for the debate, excluding the user's country. 
    Provide only the country names, separated by commas, without any additional text.
    """
    response = get_gemini_response(prompt)
    countries = [country.strip() for country in response.split(',') if country.strip() != user_country]
    
    # If less than 3 countries are provided, generate placeholders
    while len(countries) < 3:
        countries.append(f"Country {len(countries) + 1}")
    
    return countries[:3]  # Return exactly 3 countries

# Function to generate responses for each debate stage
def generate_ambassador_responses(topic, user_country, stage):
    countries = assign_countries_based_on_topic(topic, user_country)
    if stage == 0:
        # Prompts for the introduction stage of the debate
        prompts = [
            f"As the Chair, briefly introduce the topic '{topic}' in about 50 words.",
            f"As Ambassador A from {countries[0]}, introduce yourself and provide a concise supportive argument for '{topic}' in about 50 words.",
            f"As Ambassador B from {countries[1]}, introduce yourself and provide a brief skeptical argument against '{topic}' in about 50 words.",
            f"As Ambassador C from {countries[2]}, introduce yourself and provide a short balanced perspective on '{topic}' in about 50 words.",
            f"As the Chair, briefly ask the delegate from {user_country} if they would like to speak, in about 30 words."
        ]
    else:
        # Prompts for the second stage (after the user speaks)
        prompts = [
            f"As Ambassador A from {countries[0]}, respond to {user_country}'s delegate or bring a new supporting argument for '{topic}' in about 50 words.",
            f"As Ambassador B from {countries[1]}, respond to {user_country}'s delegate or bring a new argument against '{topic}' in about 50 words.",
            f"As Ambassador C from {countries[2]}, provide a brief balanced perspective on recent arguments about '{topic}' in about 50 words.",
            f"As the Chair, summarize recent points and ask about further motions or voting in about 50 words."
        ]

    # Generate responses for each prompt using the Gemini AI
    responses = [get_gemini_response(prompt) for prompt in prompts]
    return responses

# Function to convert text to speech using gTTS (Google Text-to-Speech)
def text_to_speech_gtts(text):
    tts = gTTS(text=text, lang="en")
    temp_dir = tempfile.gettempdir()  # Create a temporary directory for storing audio files
    temp_file = os.path.join(temp_dir, f"speech_{os.urandom(8).hex()}.mp3")
    tts.save(temp_file)  # Save the audio file
    return temp_file

# Default route for testing if the API is running
@app.route("/")
def index():
    return send_from_directory(".", "index.html")

# Main route for handling the debate chat requests
@app.route("/chat", methods=["POST"])
def chat_endpoint():
    global conversation_history, user_country, debate_stage, topic
    data = request.json  # Get JSON data from the frontend
    recognized_text = data.get("message", "")  # Get the user's message

    if not recognized_text:
        return jsonify({"error": "No message provided"}), 400

    try:
        if debate_stage == 0:
            # If this is the first stage of the debate, extract topic and country
            parts = recognized_text.split(", ")
            if len(parts) >= 2:
                topic = parts[0]
                user_country = parts[1]
            else:
                # If only one part is provided, assume it's the topic
                topic = parts[0]
                user_country = "Unspecified Country"

            debate_stage = 1  # Move to the next stage of the debate
            conversation_history.append(
                glm.Content(parts=[glm.Part(text=f"Topic: {topic}, User Country: {user_country}")], role="user")
            )
            # Generate ambassador responses for the first stage of the debate
            responses = generate_ambassador_responses(topic, user_country, 0)
            # Convert the responses to audio using gTTS
            audio_files = [text_to_speech_gtts(response) for response in responses]
            return jsonify({
                "response": responses,  # Send responses as text
                "audio_urls": [f"/audio/{os.path.basename(file)}" for file in audio_files],  # Send audio URLs
                "waitForUserInput": True
            })
        elif debate_stage == 1:
            # Handle the user's response in the second stage of the debate
            user_response = f"The delegate from {user_country} says: {recognized_text}"
            conversation_history.append(
                glm.Content(parts=[glm.Part(text=user_response)], role="user")
            )
            debate_stage = 2  # Move to the final stage of the debate
            # Generate ambassador responses after the user has spoken
            responses = generate_ambassador_responses(topic, user_country, 1)
            # Convert the responses to audio using gTTS
            audio_files = [text_to_speech_gtts(response) for response in responses]
            return jsonify({
                "response": responses,
                "audio_urls": [f"/audio/{os.path.basename(file)}" for file in audio_files],
                "waitForUserInput": False
            })
        else:
            # If debate is finished, reset the conversation
            debate_stage = 0
            conversation_history = [
                glm.Content(parts=[glm.Part(text=system_prompt)], role="user")
            ]
            return jsonify({
                "response": ["The debate is over. Thank you for participating!"],
                "audio_urls": []
            })
    except Exception as e:
        return jsonify({"error": f"Error: {str(e)}"}), 500

# Serve audio files generated from gTTS
@app.route("/audio/<filename>")
def audio_endpoint(filename):
    return send_file(os.path.join(tempfile.gettempdir(), filename))

# Main entry point to run the Flask app
if __name__ == "__main__":
    app.run(debug=True)
